{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff2b288-4b88-405c-9af0-f8242fdc8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6808f45-be2f-4b78-aa9c-093d1672953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VCF\n",
    "# ----------------------------\n",
    "# VCF loader (plain .vcf, not gzipped)\n",
    "# ----------------------------\n",
    "def load_vcf_plain_with_ids(path, keep_autosomes=True):\n",
    "    samples, meta, var_chr, cols = [], [], [], []\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"##\"):\n",
    "                continue\n",
    "            if line.startswith(\"#CHROM\"):\n",
    "                header = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "                samples = header[9:]\n",
    "                continue\n",
    "            parts = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            if len(parts) < 10:\n",
    "                continue\n",
    "            chrom, pos, _id, ref, alt, qual, flt, info, fmt = parts[:9]\n",
    "            geno = parts[9:]\n",
    "            if keep_autosomes:\n",
    "                c = chrom.replace(\"chr\", \"\")\n",
    "                if not c.isdigit():\n",
    "                    continue\n",
    "                if not (1 <= int(c) <= 22):\n",
    "                    continue\n",
    "            dos = []\n",
    "            for g in geno:\n",
    "                gt = g.split(\":\", 1)[0]\n",
    "                if gt in (\"./.\", \".|.\"):\n",
    "                    dos.append(np.nan)\n",
    "                else:\n",
    "                    a = gt.replace(\"|\", \"/\").split(\"/\")\n",
    "                    try:\n",
    "                        dos.append(sum(int(x) for x in a))\n",
    "                    except:\n",
    "                        dos.append(np.nan)\n",
    "            meta.append((chrom, int(pos), ref, alt))\n",
    "            var_chr.append(chrom.replace(\"chr\", \"\"))\n",
    "            cols.append(np.asarray(dos, dtype=float))\n",
    "    G = np.vstack(cols).T if cols else np.empty((len(samples), 0))\n",
    "    return samples, meta, var_chr, G\n",
    "\n",
    "#real_samples, real_meta, VAR_CHR, G_real = load_vcf_plain_with_ids(REAL_VCF)\n",
    "#print(\"Loaded REAL:\", G_real.shape, \" (samples × SNPs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfe42a2-11d3-4b6a-ac2d-181693a957ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= Leaky baseline generator =================\n",
    "\n",
    "def _flip_genotypes(dos_row, flip_rate=0.01, rng=None, keep_ultra_rare_mask=None):\n",
    "    \"\"\"\n",
    "    dos_row: 1D float array in {0,1,2} or NaN\n",
    "    flip_rate: per-SNP probability to perturb genotype by ±1 (clipped to [0,2])\n",
    "    keep_ultra_rare_mask: boolean mask (m,) -> variants to *avoid* flipping (preserve leakage)\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "    out = dos_row.copy()\n",
    "    m = out.shape[0]\n",
    "    flips = rng.random(m) < flip_rate\n",
    "    if keep_ultra_rare_mask is not None:\n",
    "        flips = flips & (~keep_ultra_rare_mask)  # DO NOT touch ultra-rare variants\n",
    "    # only flip where not NaN\n",
    "    valid = ~np.isnan(out)\n",
    "    idx = np.where(flips & valid)[0]\n",
    "    if idx.size:\n",
    "        step = rng.choice([-1.0, 1.0], size=idx.size)\n",
    "        out[idx] = np.clip(out[idx] + step, 0.0, 2.0)\n",
    "    return out\n",
    "\n",
    "def make_ultra_rare_mask(G, maf_thresh=0.001, eps=1e-9):\n",
    "    \"\"\"\n",
    "    Returns boolean mask of variants that are ultra-rare in the provided matrix G (NaN tolerated).\n",
    "    \"\"\"\n",
    "    G = np.asarray(G, dtype=float)\n",
    "    # AF from cohort (ignoring NaN)\n",
    "    sums = np.nansum(G, axis=0)  # sum of dosages\n",
    "    nobs = np.sum(~np.isnan(G), axis=0)  # number of non-NaN\n",
    "    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "        p = np.where(nobs > 0, (sums / 2.0) / nobs, 0.0)\n",
    "    maf = np.minimum(p, 1.0 - p)\n",
    "    return (maf + eps) < maf_thresh\n",
    "\n",
    "def generate_leaky_copycat(\n",
    "    G_real,\n",
    "    n_samples: int | None = None,\n",
    "    copy_frac=0.60,\n",
    "    neardup_frac=0.30,\n",
    "    random_frac=0.10,\n",
    "    flip_rate_neardup=0.01,\n",
    "    flip_rate_random=0.05,\n",
    "    keep_ultra_rare=True,\n",
    "    ultra_maf=0.001,\n",
    "    seed=123\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a leaky cohort from G_real (n_real x m) of size n_samples (defaults to n_real).\n",
    "    Fractions refer to the *output* size and must sum to 1.\n",
    "    \"\"\"\n",
    "    assert abs(copy_frac + neardup_frac + random_frac - 1.0) < 1e-9\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_real, m = G_real.shape\n",
    "    if n_samples is None:\n",
    "        n_samples = n_real\n",
    "\n",
    "    keep_rare_mask = make_ultra_rare_mask(G_real, maf_thresh=ultra_maf) if keep_ultra_rare else None\n",
    "\n",
    "    n_copy = int(round(copy_frac * n_samples))\n",
    "    n_near = int(round(neardup_frac * n_samples))\n",
    "    n_rand = n_samples - n_copy - n_near\n",
    "\n",
    "    base_idx = rng.choice(n_real, size=n_samples, replace=True)\n",
    "    Gb = G_real[base_idx, :]\n",
    "\n",
    "    rows = []\n",
    "    rows.extend(Gb[:n_copy, :])  # exact copies\n",
    "\n",
    "    for i in range(n_copy, n_copy + n_near):\n",
    "        rows.append(_flip_genotypes(Gb[i, :], flip_rate=flip_rate_neardup,\n",
    "                                    rng=rng, keep_ultra_rare_mask=keep_rare_mask))\n",
    "    for i in range(n_copy + n_near, n_copy + n_near + n_rand):\n",
    "        rows.append(_flip_genotypes(Gb[i, :], flip_rate=flip_rate_random,\n",
    "                                    rng=rng, keep_ultra_rare_mask=keep_rare_mask))\n",
    "\n",
    "    return np.vstack(rows)\n",
    "\n",
    "def generate_leaky_kindoped(\n",
    "    G_real,\n",
    "    n_samples: int | None = None,\n",
    "    # base mix (copycat-ε)\n",
    "    copy_frac=0.50,\n",
    "    neardup_frac=0.40,\n",
    "    random_frac=0.10,\n",
    "    flip_rate_neardup=0.008,\n",
    "    flip_rate_random=0.03,\n",
    "    # kin-doping controls (on the *output*)\n",
    "    dup_pairs_frac=0.20,\n",
    "    sib_flip_rate=0.008,\n",
    "    keep_ultra_rare=True,\n",
    "    ultra_maf=0.001,\n",
    "    seed=123\n",
    "):\n",
    "    \"\"\"\n",
    "    Copycat-ε + kin-doping. Output size = n_samples (defaults to n_real).\n",
    "    dup_pairs_frac: fraction of output rows to turn into sibling-like near-dups.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_real, m = G_real.shape\n",
    "    if n_samples is None:\n",
    "        n_samples = n_real\n",
    "\n",
    "    # Step 1: base leaky cohort of size n_samples\n",
    "    G_base = generate_leaky_copycat(\n",
    "        G_real, n_samples=n_samples,\n",
    "        copy_frac=copy_frac, neardup_frac=neardup_frac, random_frac=random_frac,\n",
    "        flip_rate_neardup=flip_rate_neardup, flip_rate_random=flip_rate_random,\n",
    "        keep_ultra_rare=keep_ultra_rare, ultra_maf=ultra_maf, seed=seed\n",
    "    )\n",
    "\n",
    "    # Step 2: kin-doping\n",
    "    k = int(round(dup_pairs_frac * n_samples))\n",
    "    if k > 0:\n",
    "        idx = rng.choice(n_samples, size=k, replace=False)\n",
    "        for i in idx:\n",
    "            G_base[i, :] = _flip_genotypes(G_base[i, :], flip_rate=sib_flip_rate, rng=rng)\n",
    "\n",
    "    return G_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad37ff38-8987-4776-834e-ab8159b0c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vcf_from_matrix(out_path, samples, meta, G, ref_keep_chr_format=\"as_is\"):\n",
    "    \"\"\"\n",
    "    Minimal VCF writer: writes GT only. Generates as many sample IDs as there are rows in G.\n",
    "    \"\"\"\n",
    "    n, m = G.shape\n",
    "    # Generate IDs deterministically; use original names when available, pad otherwise\n",
    "    base = [f\"{s}_LEAKY\" for s in samples]\n",
    "    if n <= len(base):\n",
    "        new_samples = [f\"{base[i]}{i:04d}\" for i in range(n)]\n",
    "    else:\n",
    "        # use all provided names, then synthesize more\n",
    "        new_samples = [f\"{base[i]}{i:04d}\" for i in range(len(base))]\n",
    "        new_samples += [f\"LEAKY_{i:04d}\" for i in range(len(base), n)]\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"##fileformat=VCFv4.2\\n\")\n",
    "        f.write(\"##FORMAT=<ID=GT,Number=1,Type=String,Description=\\\"Genotype\\\">\\n\")\n",
    "        header = [\"#CHROM\",\"POS\",\"ID\",\"REF\",\"ALT\",\"QUAL\",\"FILTER\",\"INFO\",\"FORMAT\"] + new_samples\n",
    "        f.write(\"\\t\".join(header) + \"\\n\")\n",
    "        for j in range(m):\n",
    "            chrom, pos, ref, alt = meta[j]\n",
    "            if ref_keep_chr_format == \"strip_chr\":\n",
    "                chrom = str(chrom).replace(\"chr\",\"\")\n",
    "            col = G[:, j]\n",
    "            gts = []\n",
    "            for d in col:\n",
    "                if np.isnan(d):\n",
    "                    gts.append(\"./.\")\n",
    "                else:\n",
    "                    d = int(round(d))\n",
    "                    if d <= 0: gts.append(\"0/0\")\n",
    "                    elif d == 1: gts.append(\"0/1\")\n",
    "                    else: gts.append(\"1/1\")\n",
    "            row = [str(chrom), str(pos), \".\", str(ref), str(alt), \".\", \"PASS\", \".\", \"GT\"] + gts\n",
    "            f.write(\"\\t\".join(row) + \"\\n\")\n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2059795-f0b4-49f5-90a8-83876706d2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded REAL: (2504, 65535)  (samples × SNPs)\n",
      "Leaky baseline written to: LEAKY_copycat_chr1.vcf with shape (2500, 65535)\n"
     ]
    }
   ],
   "source": [
    "REAL_VCF = \"1000G_65K_SNP_chr1.vcf\"\n",
    "\n",
    "# Load REAL *after* defining the path\n",
    "real_samples, real_meta, VAR_CHR, G_real = load_vcf_plain_with_ids(REAL_VCF)\n",
    "print(\"Loaded REAL:\", G_real.shape, \" (samples × SNPs)\")\n",
    "\n",
    "# Choose output size for leaky baselines (match your GAN/RBM if you want)\n",
    "N_SYN = 2500\n",
    "\n",
    "# Copycat-ε leaky set of size N_SYN\n",
    "G_leaky = generate_leaky_copycat(\n",
    "    G_real,\n",
    "    n_samples=N_SYN,\n",
    "    copy_frac=0.80,\n",
    "    neardup_frac=0.15,\n",
    "    random_frac=0.05,\n",
    "    flip_rate_neardup=0.003,\n",
    "    flip_rate_random=0.05,\n",
    "    keep_ultra_rare=True,\n",
    "    ultra_maf=0.001,\n",
    "    seed=777\n",
    ")\n",
    "LEAKY_VCF = \"LEAKY_copycat_chr1.vcf\"\n",
    "write_vcf_from_matrix(LEAKY_VCF, real_samples, real_meta, G_leaky)\n",
    "print(\"Leaky baseline written to:\", LEAKY_VCF, \"with shape\", G_leaky.shape)\n",
    "\n",
    "# Kin-doped leaky set of size N_SYN\n",
    "G_leaky_hot = generate_leaky_kindoped(\n",
    "    G_real,\n",
    "    n_samples=N_SYN,\n",
    "    dup_pairs_frac=0.20,\n",
    "    sib_flip_rate=0.08,\n",
    "    seed=888\n",
    ")\n",
    "write_vcf_from_matrix(\"LEAKY_kindoped_chr1.vcf\", real_samples, real_meta, G_leaky_hot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "prism"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
